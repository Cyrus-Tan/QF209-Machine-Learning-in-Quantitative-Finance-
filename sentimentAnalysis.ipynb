{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following statement imports the NLTK package.\n",
    "import nltk\n",
    "\n",
    "# The following statement imports a class called PlaintextCorpusReader.\n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import sent_tokenize\n",
    "import string\n",
    "import re \n",
    "\n",
    "import tqdm as notebook_tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# instantiate finBERT\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, pipeline\n",
    "finbert = BertForSequenceClassification.from_pretrained('yiyanghkust/finbert-tone',num_labels=3)\n",
    "tokenizer = BertTokenizer.from_pretrained('yiyanghkust/finbert-tone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Data/BA_transcripts/2016-Jan-28-BA.N-138020839119-Transcript.txt', 'Data/BA_transcripts/2015-Apr-22-BA.N-140063175207-Transcript.txt', 'Data/BA_transcripts/2022-Oct-26-BA.N-140697322944-Transcript.txt', 'Data/BA_transcripts/2010-Jul-28-BA.N-137028827968-Transcript.txt', 'Data/BA_transcripts/2014-Jan-29-BA.N-139067099110-Transcript.txt']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# loop through text file in Data\n",
    "rootdir = 'Data'\n",
    "filelist = []\n",
    "for subdir, dirs, files in os.walk(rootdir):\n",
    "    for file in files:\n",
    "        filename = os.path.join(subdir, file)\n",
    "        filelist.append(filename)\n",
    "\n",
    "filelist = filelist[1:6]\n",
    "# to be changed to the full list\n",
    "print(filelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textPreprocessing(filename):\n",
    "    # load text\n",
    "    file = open(filename, 'rt')\n",
    "    text = file.read()\n",
    "    file.close()\n",
    "\n",
    "    # tokenize into sentences\n",
    "    tokens = sent_tokenize(text)\n",
    "\n",
    "    # alpha to lowercase\n",
    "    tokens = [w.lower() for w in tokens]\n",
    "\n",
    "    # remove punctuation and whitespaces\n",
    "    remove = string.punctuation\n",
    "    remove = re.sub(r\"[-]+\", \"\", remove)\n",
    "    pattern = r\"[{}]\".format(remove + '-')\n",
    "    clean_list = []\n",
    "\n",
    "    for sentence in tokens:\n",
    "        sentence = re.sub(pattern, \"\", sentence) \n",
    "        sentence = sentence.split()\n",
    "        sentence = ' '.join(sentence)\n",
    "        clean_list.append(sentence)\n",
    "\n",
    "    return clean_list\n",
    "\n",
    "# no neeed to remove stopwords and conduct lemmatization\n",
    "# may worsen prediction for transformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that takes returns a document level sentiment score\n",
    "\n",
    "def sentimentAnalysis(filename):\n",
    "    clean_list = textPreprocessing(filename)\n",
    "    # pipeline: API that wraps finBERT sentiment analysis \n",
    "    nlp = pipeline(\"sentiment-analysis\", model=finbert, tokenizer=tokenizer)\n",
    "    results = nlp(clean_list)\n",
    "    \n",
    "    negative = 0\n",
    "    positive = 0\n",
    "    for element in results:\n",
    "        if element['label'] == \"Negative\":\n",
    "            negative += 1\n",
    "        elif element['label'] == \"Positive\":\n",
    "            positive += 1\n",
    "    total = len(results)\n",
    "\n",
    "    sentiment_score = (positive - negative)/ total\n",
    "    return sentiment_score\n",
    "\n",
    "    # +ve sentiment score: positive earnings call\n",
    "    # -ve sentiment score: negative earnings call\n",
    "\n",
    "    # https://www.alpha-sense.com/blog/engineering/sentiment-score/\n",
    "    # sentiment score: (positive - negative) / total number of statements\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.29038112522686027, 0.1873873873873874, 0.0865561694290976, 0.052884615384615384, 0.25766871165644173]\n"
     ]
    }
   ],
   "source": [
    "sentiment_score_list = []\n",
    "for filename in filelist:\n",
    "    sentiment_score = sentimentAnalysis(filename)\n",
    "    sentiment_score_list.append(sentiment_score)\n",
    "\n",
    "print(sentiment_score_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # stopword removal\n",
    "# from nltk.corpus import stopwords\n",
    "# stop_words = set(stopwords.words('english'))\n",
    "# words = [w for w in words if not w in stop_words]\n",
    "# print(words[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # lemmatization\n",
    "# from nltk.stem import WordNetLemmatizer\n",
    "# lemmatizer = WordNetLemmatizer()\n",
    "# lemmatized = [lemmatizer.lemmatize(word) for word in words]\n",
    "# print(lemmatized) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
